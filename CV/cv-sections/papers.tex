\cvsection{Papers}

\begin{cventries}
	
\cventry
{Dmitry Kovalev, Konstantin Mishchenko, Peter Richtárik} % Role
{Stochastic Newton and Cubic Newton Methods with Simple Local Linear-Quadratic Rates} % Title
{} % Location
{Dec. 2019} % Date(s)
{ % Description(s)
	\begin{cvitems}
		\item {\href{https://sites.google.com/site/optneurips19/}{NeurIPS 2019 Workshop: Beyond First Order Methods in Machine Learning}}
		\item {\href{https://arxiv.org/pdf/1912.01597.pdf}{arXiv 2019}}		
	\end{cvitems}
}	

\cventry
{Mohammad Alkousa, Darina Dvinskikh, Fedor Stonyakin, Alexander Gasnikov, Dmitry Kovalev} % Role
{Accelerated methods for composite non-bilinear saddle point problem} % Title
{} % Location
{Dec. 2019} % Date(s)
{ % Description(s)
	\begin{cvitems}
		\item {\href{https://arxiv.org/abs/1906.03620}{arXiv 2019}}
	\end{cvitems}
}	

\cventry
{Adil Salim, Dmitry Kovalev, Peter Richtárik} % Role
{Stochastic Proximal Langevin Algorithm: Potential Splitting and Nonasymptotic Rates} % Title
{} % Location
{May 2019} % Date(s)
{ % Description(s)
	\begin{cvitems}
		\item {\href{https://papers.nips.cc/paper/8891-stochastic-proximal-langevin-algorithm-potential-splitting-and-nonasymptotic-rates}{NeurIPS 2019}}
	\end{cvitems}
}	
	
\cventry
{Konstantin Mishchenko, Dmitry Kovalev, Egor Shulgin, Peter Richtárik, Yura Malitsky} % Role
{Revisiting Stochastic Extragradient} % Title
{} % Location
{May 2019} % Date(s)
{ % Description(s)
	\begin{cvitems}
		\item {\href{https://sgo-workshop.github.io}{NeurIPS 2019 Workshop: Bridging Game Theory and Deep Learning}}
		\item {\href{https://arxiv.org/abs/1905.11373}{arXiv 2019}}
	\end{cvitems}
}

\cventry
{Robert M. Gower, Dmitry Kovalev, Felix Lieder, Peter Richtárik} % Role
{RSN: Randomized Subspace Newton} % Title
{} % Location
{May 2019} % Date(s)
{ % Description(s)
	\begin{cvitems}
		\item {\href{https://papers.nips.cc/paper/8351-rsn-randomized-subspace-newton}{NeurIPS 2019}}
	\end{cvitems}
}

\cventry
{Samuel Horváth, Dmitry Kovalev, Konstantin Mishchenko, Peter Richtárik, Sebastian U. Stich} % Role
{Stochastic Distributed Learning with Gradient Quantization and Variance Reduction} % Title
{} % Location
{Jan. 2019} % Date(s)
{ % Description(s)
	\begin{cvitems}
		\item {\href{https://arxiv.org/abs/1904.05115}{arXiv 2019}}
	\end{cvitems}
}

\cventry
{Dmitry Kovalev, Samuel Horváth, Peter Richtárik} % Role
{Don't Jump Through Hoops and Remove Those Loops: SVRG and Katyusha are Better Without the Outer Loop} % Title
{} % Location
{Jan. 2019} % Date(s)
{ % Description(s)
	\begin{cvitems}
		\item {\href{https://arxiv.org/abs/1901.08689}{arXiv 2019}}
	\end{cvitems}
}


\cventry
{Alexander Gasnikov, Dmitry Kovalev	} % Role
{A hypothesis about the rate of global convergence for optimal methods (Newton's type) in smooth convex optimization } % Title
{} % Location
{Feb. 2018} % Date(s)
{ % Description(s)
	\begin{cvitems}
		\item {\href{http://www.mathnet.ru/php/archive.phtml?wshow=paper\&jrnid=crm\&paperid=253\&option\_lang=eng}{
				Computer Research and Modeling, 2018,	Volume 10,	Issue 3,	Pages 305–314}}
	\end{cvitems}
}


\cventry
{Dmitry Kovalev, Eduard Gorbunov, Elnur Gasanov, Peter Richtárik} % Role
{Stochastic Spectral and Conjugate Descent Methods} % Title
{} % Location
{Feb. 2018} % Date(s)
{ % Description(s)
\begin{cvitems}
\item {\href{https://papers.nips.cc/paper/7596-stochastic-spectral-and-conjugate-descent-methods}{NeurIPS 2018}}
\end{cvitems}
}



\end{cventries}